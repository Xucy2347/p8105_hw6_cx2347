---
title: "p8105_hw6_cx2347"
author: "Chuyuan XU"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, message=FALSE}
library(tidyverse)
library(stringr)
library(broom)
library(patchwork)
library(glmnet)
library(modelr)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 8,
  fig.asp = 0.9,
  out.width = "90%"
)
```

### Problem 1
```{r p1 import, message=FALSE}
csv = "https://raw.githubusercontent.com/washingtonpost/data-homicides/refs/heads/master/homicide-data.csv"

homicide_raw = read_csv(csv, na=c("NA", "", "."))
```

```{r p1 tidy}
homicide_df = homicide_raw |>
  janitor::clean_names() |>
  
  # Create a city_state variable (e.g. “Baltimore, MD”)
  mutate(city_state = str_c(city, ', ', state)) |>
  
  # omit Dallas, TX; Phoenix, AZ; Kansas City, MO; Tulsa, AL
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")
  ) |>
  
  # limit the data among those for whom victim_race is white or black
  filter(
    victim_race %in% c("White", "Black")
  ) |>
  
  # change the victims' age into numbers
  # change the unknown victims' sex into NA
  # change the victim_race into a factor
  # create a indicator for resolved vs unresolved
  mutate(
    victim_age = if_else(victim_age == "Unknown", NA , victim_age),
    victim_age = as.numeric(victim_age),
    victim_sex =  if_else(victim_sex == "Unknown", NA , victim_sex),
    victim_race = fct_relevel(victim_race, "White"),
    resolved = as.numeric(disposition == "Closed by arrest")
  )
```

```{r, p1 glm_Balt}
# fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors
fit_balt = homicide_df |>
  filter(city == "Baltimore") |>
  glm(
    resolved ~ victim_age + victim_race + victim_sex, 
    data = _,
    family = binomial()
  )

fit_balt_df = fit_balt |> 
  broom::tidy() |> 
  mutate(
    OR = exp(estimate),
    conf.low = exp(estimate - 1.96*std.error),
    conf.high = exp(estimate + 1.96*std.error),
  ) |>
  select(term, OR, conf.low, conf.high, p.value) 

fit_balt_df |> 
  mutate(
    conf.low = round(conf.low, 3),
    conf.high = round(conf.high, 3)
  ) |>
  nest(CI = c("conf.low", "conf.high")) |>
  select(term, OR, CI, p.value) |>
  knitr::kable(
    digits = 3,
    col.names = c("terms", "est OR", "95% CI (OR)", "P-value"),
    align = 'r'
  )
```

The estimated adjusted odds ratio for solving homicides comparing male victims to female victims keeping all other variables fixed is `r round(pull(filter(fit_balt_df, term == "victim_sexMale"), OR),3)`, with a 95% confidence interval of (`r round(pull(filter(fit_balt_df, term == "victim_sexMale"), conf.low), 3)`, `r round(pull(filter(fit_balt_df, term == "victim_sexMale"), conf.high),3)`).

```{r p1 glm_all cities}
glm_cities_df = homicide_df |>
  nest(data = -city_state) |>
  mutate(
    models = map(data, \(df) glm(resolved ~ victim_age + victim_race + victim_sex, data = df)),
    results = map(models, broom::tidy)
  ) |>
  select(-data, -models) |> 
  unnest(results) |>
  
  # keep the results for only adj OR males over females
  filter(term == "victim_sexMale") |>
  
  mutate(
    OR = exp(estimate),
    conf.low = exp(estimate - 1.96*std.error),
    conf.high = exp(estimate + 1.96*std.error)
  ) |> 
  select(city_state, OR, conf.low, conf.high, p.value) |>
  
  # Organize cities according to estimated OR
  mutate(
    city_state = fct_reorder(city_state, OR)
  ) |>
  arrange(city_state)
```

```{r p1 plot}
# Create a plot that shows the estimated ORs and CIs for each city.
glm_cities_df |>
  mutate(
    fill = (OR > 1)
  ) |>
  ggplot(aes(y = city_state, x = OR, color = fill)) +
  geom_point() +
  geom_errorbar(
    aes(xmin = conf.low, xmax = conf.high),
    width = 0.2,
    alpha = 0.8
  ) +
  geom_vline(
    aes(xintercept = 1.0), 
    color = "grey",
    alpha = 0.8
  ) +
  theme_minimal() +
  labs(
    y = 'City, State',
    x = 'the Estimated OR with 95% CI',
    color = 'OR is greater than 1.0',
    title = 'the Adjusted Odds Ratio (and 95% CI) for Solving Homicides',
    subtitle = 'Comparing Male Victims to Female Victims'
  )
```

#### Comments:
6 of 47 cities in the study have an OR greater than 1, for solving homicides comparing male and female victims. In most cities, the odds for solving homicides with a male victims is lower than that for solving homicides with a female victims, adjusting for their age and race (white or black). However, many 95% CI of the adjusted OR include the null value of 1, we cannot conclude those associations are significant.


### Problem 2
```{r p2 import}
data("weather_df")
```

```{r p3 bootstrap}
weather_bs = weather_df |>
  modelr::bootstrap(n = 5000) |>
  mutate(
    models = map(strap, \(df) lm(tmax ~ tmin + prcp, data = df))
  )

# get the r_sqr
weather_rsq = weather_bs |>
  mutate(
    results = map(models, broom::glance)
  ) |>
  unnest(results) |>
  mutate(
    id = as.numeric(.id)
  ) |>
  select(id = id, r.squared)

# get the beta_1/beta_2
weather_betas = weather_bs |>
  mutate(
    results = map(models, broom::tidy)
  ) |>
  select(.id, results) |>
  unnest(results) |>
  select(.id, term, estimate) |>
  pivot_wider(
    names_from = "term",
    values_from = "estimate",
    id_cols = .id
  ) |>
  mutate(
    beta.frac = tmin/prcp,
    id = as.numeric(.id)
  ) |>
  select(id, beta.frac)

# merge the result into one
weather_bs_rslt = full_join(weather_rsq, weather_betas, by = "id")
```

```{r p2 dist plot}
rsqr.dist = weather_bs_rslt |>
  ggplot(aes(x = r.squared)) +
  geom_density(fill = 'grey', alpha = 0.4) +
  geom_vline(aes(xintercept = mean(r.squared)), color = 'red', linetype = "dashed", alpha = 0.5) +
  geom_vline(aes(xintercept = median(r.squared)), color = 'blue', linetype = "solid", alpha = 0.8) +
  labs(
    x = "R sqaured"
  ) +
  theme_minimal()

beta.frac_dist = weather_bs_rslt |>
  ggplot(aes(x = beta.frac)) +
  geom_density(fill = 'grey', alpha = 0.4) +
  geom_vline(aes(xintercept = mean(beta.frac)), color = 'red', linetype = "dashed", alpha = 0.5) +
  geom_vline(aes(xintercept = median(beta.frac)), color = 'blue', linetype = "solid", alpha = 0.8) +
  labs(
    x = "Beta_tmin/Beta_prcp",
    y = ""
  ) +
  theme_minimal()

rsqr.dist + beta.frac_dist +
  plot_annotation(
    title = 'the Distribution of the Estimates',
    caption = 'the red dashed line is the mean and the blue solid line is the median')
```

The above figure displays the distribution of Estimated Beta_tmin/Beta_prcp and R-squared, where the red dashed line is the mean and the blue solid line is the median. The r-squared is approximately symmetrically distributed with a range of 0.930 and 0.955. The Beta_tmin/Beta_prcp r-squared has a left-skewed distribution, with a range between -450 and -100.

```{r p2 quantiles}
q = weather_bs_rslt |>
  pivot_longer(
    cols = r.squared:beta.frac,
    values_to = "estimate",
    names_to = "terms"
  ) |>
  group_by(terms) |>
  summarize(
    ci_lower = quantile(estimate, 0.025), 
    ci_upper = quantile(estimate, 0.975)
  ) |>
  mutate(
    terms = case_match(
      terms,
      "beta.frac" ~ "est(Beta_tmin/Beta_prcp)",
      "r.squared" ~ "R-squared"
      )
    )

q |>
  knitr::kable(
    digits = 3,
    col.names = c("Estimates", "2.5% quantiles", "97.5% quantiles"),
    caption = "the 95% Confidence Intervals for Estimates"
  )
```

The above table shows the 95% Confidence Intervals for the Estimated Beta_tmin/Beta_prcp and R-squared.

### Problem 3
```{r p3 import}
bwt_raw = read_csv("data/birthweight.csv", na = c("NA", ".", ""))
```

```{r p3 tidy}
bwt_df = bwt_raw |>
    mutate(
      babysex = 
          case_match(babysex,
              1 ~ "male",
              2 ~ "female"
          ),
      
      babysex = fct_infreq(babysex),
      
      frace = 
          case_match(frace,
              1 ~ "white",
              2 ~ "black", 
              3 ~ "asian", 
              4 ~ "puerto rican", 
              8 ~ "other"),
      frace = fct_infreq(frace),
    
      mrace = 
          case_match(mrace,
              1 ~ "white",
              2 ~ "black", 
              3 ~ "asian", 
              4 ~ "puerto rican",
              8 ~ "other"),
      mrace = fct_infreq(mrace),
      
      malform = as.logical(malform)
    ) 

bwt_na = bwt_df |>
  filter(if_any(everything(), is.na)) |>
  summarise(
    across(
      everything(),
      ~ sum(is.na(.))
    )
  ) |>
  pivot_longer(
    cols = c("babysex":"wtgain"),
    values_to = "na_counts",
    names_to = "var_names"
  )
```

There are `r nrow(bwt_df)` observations in the weightbirth raw dataset (`bwt_raw`) with `r ncol(bwt_df)` variables.\
Categorical variables, including baby’s sex (`babysex`), the presence of malformations that could affect weight (`malform`), father's and mother's race (`frace` and `mrace`) were converted from numeric to factor prior to the analysis. Father's and mother's race as "unknown" (category 9) will be treated as NA in the later analysis.\
After tidying the data, there are `r sum(bwt_na$na_counts)` observations with missing values.

```{r p3_lasso model selection}
# select model with Lasso
x = model.matrix(bwt ~ ., bwt_df)[,-1]
y = bwt_df |> pull(bwt)
lambda = 10^(seq(-2, 2.75, 0.1))

lasso_fit =
  glmnet(x, y, lambda = lambda)

lasso_cv =
  cv.glmnet(x, y, lambda = lambda)

lambda_opt = lasso_cv[["lambda.min"]]

lasso_fit_opt =  
  glmnet(x, y, lambda = lambda_opt) |> 
  broom::tidy()
```

A Lasso Regression model is performed to select the most parsimonious model with the smallest tuning parameter lambda. The optimized model has a lambda value of `r round(lambda_opt, 3)` and kept `r pull(lasso_fit_opt, term)[2:nrow(lasso_fit_opt)]` in the linear regression model. However, in the lasso, dummy variables for mrace and frace are separated. In the proposed model, all the frace and mrace categories are dropped.

```{r p3_refit}
# in the lasso, categorical variables for mrace and frace are separated.
# reintroduce all the frace and mrace categories.
fit_new = 
  lm(
    bwt ~ 
      bhead + blength + delwt + fincome + gaweeks + menarche + 
      mheight + momage + parity + smoken + wtgain, 
    data = bwt_df)

fit_new |>
  broom::tidy() |>
  knitr::kable(
    digits = 3,
    caption = "Summary of the new fitted Linear Regression Model Estimating Baby Birthweight"
  )

fit_new |>
  broom::glance() |>
  select(r.squared, statistic, p.value) |>
  knitr::kable(
    digits = 3,
    caption = "Performance Summary"
  )
```

The above table displays the estimate coefficient of the predictors in the linear regression model estimating baby birth weights. All of the estimates shows either significant or approximately significant association with the baby birthweight. The overall model is significant with a p-value < 0.05, and 70.5% variance in the birthweight can be explained by the model.

```{r p3_residuals vs. fitted values}
# plot of model residuals against fitted values
bwt_df |>
  modelr::add_residuals(fit_new) |>
  modelr::add_predictions(fit_new) |>
  
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  geom_smooth(method = "lm") + 
  theme_minimal() +
  labs(
    x = "Fitted Values",
    y = "Model Residuals",
    title = "Model Residuals against Fitted Values"
  )

```

```{r p3_model comparison, Warning = FALSE}
train_df = 
  crossv_mc(bwt_df, 100) |>
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )

cv_df = train_df|>
  mutate(
    # model 1 using length at birth and gestational age as predictors (main effects only)
    main_mod = 
      map(train, 
          \(df) 
          lm(
            bwt ~ 
              blength + gaweeks, 
            data = df)
          ),
    
    # model 2 using head circumference, length, sex, and all interactions (including the three-way interaction) between these
    inter_mod  = 
      map(train, 
          \(df) 
          lm(
            bwt ~ 
              bhead + blength + babysex + 
              bhead * blength + babysex * bhead + blength * babysex + 
              bhead * blength * babysex,
            data = df)
          ),
    
    # model 3: model proposed above
    my_mod  = 
      map(train, 
          \(df) 
            lm(
              bwt ~ 
                bhead + blength + delwt + fincome + gaweeks + menarche + 
                mheight + momage + parity + smoken + wtgain, 
              data = df)
            )
    ) |> 
  
  mutate(
    rmse_main = map2_dbl(main_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_inter = map2_dbl(inter_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_my = map2_dbl(my_mod, test, \(mod, df) rmse(model = mod, data = df))
    )
```

```{r p3_plot rmse}
# plot the prediction error distribution for each candidate model
cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |>
  
  ggplot(aes(x = model, y = rmse, fill = model)) + 
  geom_violin(alpha = 0.5) +
  theme_minimal() +
  labs(
    fill = "Model"
  )
```

Across all three models, the model from Lasso selection has the lowest rmse and is, therefore, more preferred.